{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd37e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import date,datetime\n",
    "import os, sys\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fabe053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "url = 'https://www.forbes.com/news_sitemap.xml'\n",
    "today=date.today()\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H_%M\")\n",
    "name=f\"sitemap__forbes_news_{today}__{current_time}.xml\"\n",
    "file_path=os.path.join(\"./xml\",name)\n",
    "filename = wget.download(url,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf1aef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename, 'r',encoding='utf-8') as file:\n",
    "    xml_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44fb32bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(xml_content, 'xml')\n",
    "urls = soup.find_all(\"url\")\n",
    "\n",
    "data = []\n",
    "for url in urls:\n",
    "    loc = url.loc.text\n",
    "    title = url.find(\"news:title\").text\n",
    "    language = url.find(\"news:language\").text\n",
    "    publication_date = url.find(\"news:publication_date\").text[:10]\n",
    "    publication_time = url.find(\"news:publication_date\").text[11:19]\n",
    "    keywords_tag=url.find(\"news:keywords\")\n",
    "    image_loc_tag = url.find(\"image:loc\")\n",
    "    if image_loc_tag and keywords_tag is not None:\n",
    "        image_loc = image_loc_tag.text\n",
    "        keywords=keywords_tag.text\n",
    "\n",
    "    row_data = {\n",
    "        \"URL\": loc,\n",
    "        \"Title\": title,\n",
    "        \"Language\":language,\n",
    "        \"Publication Date\": publication_date,\n",
    "        \"Publication Time\": publication_time,\n",
    "        \"Keywords\":keywords,\n",
    "        \"Image URL\": image_loc,\n",
    "        }\n",
    "    data.append(row_data)    \n",
    "df = pd.DataFrame(data)\n",
    "path=\"./json\"\n",
    "df.to_json(os.path.join(path,f'sitemap_forbes_news_{today}__{current_time}.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6548939",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(path) if f.endswith(\".json\")]\n",
    "files.sort()\n",
    "last_2_files=files[-2:]\n",
    "if len(last_2_files)==2:\n",
    "    data_new=pd.read_json(f'./json/{last_2_files[1]}')\n",
    "    data_old=pd.read_json(f'./json/{last_2_files[0]}')\n",
    "    news_count = pd.DataFrame({\"Time\": [last_2_files[1][-10:-5]], \"Count\": [data_new.shape[0]]})\n",
    "    old = set(data_old['Title'])\n",
    "    new = set(data_new['Title'])\n",
    "    dif_old = old.difference(new)\n",
    "    dif_new = new.difference(old)\n",
    "    inter = old.intersection(new)\n",
    "    all_news = pd.DataFrame({\"Time\": [f'{last_2_files[0][-10:-5]} - {last_2_files[1][-10:-5]}'], \n",
    "                          \"NEW\": [len(dif_new)], \n",
    "                          \"SAME\": [len(inter)], \n",
    "                          \"EXCLUDED\": [len(dif_old)]})\n",
    "    all_news.to_csv(f'./all_news/sitemap_forbes_news_{today}__{current_time}.csv',index=False)\n",
    "    news_count.to_csv(f'./news_count/sitemap_forbes_news_{today}__{current_time}.csv',index=False)\n",
    "    \n",
    "    files_news = [f for f in os.listdir(\"./all_news\") if f.endswith(\".csv\")]\n",
    "    files_news.sort()\n",
    "    file_path = os.path.join(\"./all_news\", files_news[0])\n",
    "    data_all = pd.read_csv(file_path)\n",
    "    data_all=pd.concat([data_all,all_news],axis=0)\n",
    "    data_all.to_csv(file_path,index=False)\n",
    "    \n",
    "    count_news = [f for f in os.listdir(\"./news_count\") if f.endswith(\".csv\")]\n",
    "    count_news.sort()\n",
    "    count_path = os.path.join(\"./news_count\", count_news[0])\n",
    "    count_all = pd.read_csv(count_path)\n",
    "    count_all=pd.concat([count_all,news_count],axis=0)\n",
    "    count_all.to_csv(count_path,index=False)\n",
    "    \n",
    "else:\n",
    "    data_old=pd.read_json(f'./json/{last_2_files[0]}')\n",
    "    news_count = pd.DataFrame({\"Time\": [last_2_files[0][-10:-5]], \"Count\": [data_old.shape[0]]})\n",
    "    all_news_ = pd.DataFrame({\"Time\": [f'{last_2_files[0][-10:-5]}'], \n",
    "                          \"NEW\": [data_old.shape[0]], \n",
    "                          \"SAME\": [0], \n",
    "                          \"EXCLUDED\": [0]})\n",
    "    all_news_.to_csv(f'./all_news/all_time_news.csv',index=False)\n",
    "    news_count.to_csv(f'./news_count/all_time_news_count.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eecd30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
